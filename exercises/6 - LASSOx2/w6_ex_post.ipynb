{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6: High-Dimensional Methods and Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this week's problem set is to get familiar with inference based on high-dimensional methods.  Our focus is again on methods based on the Lasso, and we again use the <tt>housing.csv</tt> dataset. (See the previous problem set for data details.) Note how our focus has here changed from prediction (of house prices) to inference (drivers of house prices).\n",
    "\n",
    "We first read the data into Python and remove missings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows and colums are (20640, 10) and also called shape of the matrix\n",
      "Columns names are \n",
      " Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
      "       'total_bedrooms', 'population', 'households', 'median_income',\n",
      "       'median_house_value', 'ocean_proximity'],\n",
      "      dtype='object')\n",
      "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0    -122.23     37.88                41.0        880.0           129.0   \n",
      "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
      "2    -122.24     37.85                52.0       1467.0           190.0   \n",
      "3    -122.25     37.85                52.0       1274.0           235.0   \n",
      "4    -122.25     37.85                52.0       1627.0           280.0   \n",
      "\n",
      "   population  households  median_income  median_house_value ocean_proximity  \n",
      "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
      "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
      "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
      "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
      "4       565.0       259.0         3.8462            342200.0        NEAR BAY  \n",
      "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "20635    -121.09     39.48                25.0       1665.0           374.0   \n",
      "20636    -121.21     39.49                18.0        697.0           150.0   \n",
      "20637    -121.22     39.43                17.0       2254.0           485.0   \n",
      "20638    -121.32     39.43                18.0       1860.0           409.0   \n",
      "20639    -121.24     39.37                16.0       2785.0           616.0   \n",
      "\n",
      "       population  households  median_income  median_house_value  \\\n",
      "20635       845.0       330.0         1.5603             78100.0   \n",
      "20636       356.0       114.0         2.5568             77100.0   \n",
      "20637      1007.0       433.0         1.7000             92300.0   \n",
      "20638       741.0       349.0         1.8672             84700.0   \n",
      "20639      1387.0       530.0         2.3886             89400.0   \n",
      "\n",
      "      ocean_proximity  \n",
      "20635          INLAND  \n",
      "20636          INLAND  \n",
      "20637          INLAND  \n",
      "20638          INLAND  \n",
      "20639          INLAND  \n",
      "longitude             float64\n",
      "latitude              float64\n",
      "housing_median_age    float64\n",
      "total_rooms           float64\n",
      "total_bedrooms        float64\n",
      "population            float64\n",
      "households            float64\n",
      "median_income         float64\n",
      "median_house_value    float64\n",
      "ocean_proximity        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "import pandas as pd\n",
    "housing = pd.read_csv(\"housing.csv\")\n",
    "print(\"The number of rows and colums are {} and also called shape of the matrix\".format(housing.shape)) # data dimensions\n",
    "print(\"Columns names are \\n {}\".format(housing.columns))\n",
    "print(housing.head()) # first observations\n",
    "print(housing.tail()) # last observations\n",
    "print(housing.dtypes) # data types\n",
    "housing=housing.dropna() # dropping observations missing a bedroom count "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We model house prices (<tt>median_house_value</tt>) using a linear (in the parameters) model of the basic regressors (minus the categorical variable <tt>ocean_proximity</tt>),\n",
    "\n",
    "$$\n",
    "\\underbrace{\\mathtt{median\\,house\\,value}}_{=Y}=\\alpha\\times\\underbrace{\\mathtt{median\\,income}}_{=D} + Z'\\gamma + \\varepsilon,\\quad\\mathrm{E}[\\varepsilon|D,Z]=0.\n",
    "$$\n",
    "\n",
    "We here focus on constructing a confidence interval for the coefficient of <tt>median_income</tt> after having used the Lasso. In doing so we treat both <tt>median_income</tt> and the remaining ($p=7$) controls as exogenous. Moreover, we augment the above model with another linear model\n",
    "\n",
    "$$\n",
    "\\mathtt{median\\,income}=Z'\\psi + \\nu,\\quad\\mathrm{E[\\nu|Z]=0},\n",
    "$$\n",
    "\n",
    "now for <tt>median_income</tt>.\n",
    "\n",
    "(One would be hard pressed to claim that median income *causes* house price movements. This is only an exercise in the mechanics.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = housing.median_house_value\n",
    "d = housing.median_income\n",
    "Z = housing.drop([\"median_house_value\",\"median_income\",\"ocean_proximity\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "Complete the following exercises using only the eight basic regressors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "Lasso <tt>median_house_value</tt> on the controls, Z, using the (feasible) Bickel-Ritov-Tsybakov (BRT) penalty level. [Hint: Don't forget to standardize.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remember to save the residuals from the LASSO-regression (Easy way: Lasso from sklearn.linear_model has a function predict) \n",
    "# - construct the residual, so they are aligned with the post-lasso method\n",
    "#You could challenge yourself by creating functions for standardizing and/or BRT\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "X=np.column_stack((d,Z))\n",
    "\n",
    "def standardize(X):\n",
    "    X_mean = np.mean(X,axis=0)\n",
    "    X_std = np.std(X,axis=0)\n",
    "    X_stan=(X-X_mean)/X_std\n",
    "    return X_stan\n",
    "\n",
    "X_stan = standardize(X)\n",
    "Z_stan = standardize(Z)\n",
    "d_stan = standardize(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_BRT = 2389.6\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "\n",
    "def BRT(X_tilde,y):\n",
    "    (N,p)=X_tilde.shape\n",
    "    sigma = np.std(y)\n",
    "    c = 1.1\n",
    "    alpha = 0.05\n",
    "\n",
    "    penalty_BRT= (sigma * c)/np.sqrt(N)*norm.ppf(1-alpha/(2*p)) # on normalised data since sum of squares is =1, NB div by 2\n",
    "\n",
    "    return penalty_BRT\n",
    "\n",
    "penalty_BRTyz=BRT(Z_stan,y)\n",
    "\n",
    "print(\"lambda_BRT =\",penalty_BRTyz.round(2))\n",
    "\n",
    "# Lasso on median house value\n",
    "fit_BRTyz=Lasso(alpha=penalty_BRTyz).fit(Z_stan,y) #,fit_intercept = False\n",
    "\n",
    "# save residuals\n",
    "resyz=y-fit_BRTyz.predict(Z_stan) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "Lasso <tt>median_income</tt> on the controls using the (feasible) BRT penalty level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_BRT = 0.04\n"
     ]
    }
   ],
   "source": [
    "#remember to save the residuals\n",
    "\n",
    "# Lasso on median income\n",
    "penalty_BRTdz=BRT(Z_stan,d)\n",
    "\n",
    "fit_BRTdz=Lasso(alpha=penalty_BRTdz).fit(Z_stan,d) #,fit_intercept = False\n",
    "\n",
    "# save residuals\n",
    "resdz=d-fit_BRTdz.predict(Z_stan)\n",
    "print(\"lambda_BRT =\",penalty_BRTdz.round(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Partialling Out Lasso vs OLS\n",
    "Calculate the implied partialling-out Lasso estimate $\\breve{\\alpha}$ and compare with the OLS estimate $\\widehat{\\alpha}^{\\mathtt{LS}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POL =  41220.0\n",
      "LS =  [40297.52]\n"
     ]
    }
   ],
   "source": [
    "#Use your previously saved residuals\n",
    "#If you want - you can compare with OLS (why is this possible?)\n",
    "from numpy import linalg as la\n",
    "def POL_ols(x,y):\n",
    "    denom = np.sum(x**2)\n",
    "    num = np.sum(x*y)\n",
    "    return num/denom\n",
    "\n",
    "POL=POL_ols(resdz,resyz)\n",
    "print(\"POL = \",POL.round(2))\n",
    "\n",
    "N=y.shape[0]\n",
    "xx=np.column_stack((np.ones(N),X)).reshape(-1,1+X.shape[1])\n",
    "yy=np.array(y).reshape(-1,1)\n",
    "LS=la.inv(xx.T@xx)@xx.T@yy\n",
    "res_ols=yy-xx@LS\n",
    "print(\"LS = \",LS[1].round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Variance of Partialling Out Lasso\n",
    "Calculate the implied variance estimate $\\breve{\\sigma}^2$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma2_POL =  14072882476.19\n"
     ]
    }
   ],
   "source": [
    "#Use your previously saved residuals\n",
    "N = resyz.shape[0]\n",
    "num = np.sum(resdz**2*resyz**2)/N\n",
    "denom = (np.sum(resdz**2)/N)**2\n",
    "sigma2_POL = num/denom\n",
    "print(\"sigma2_POL = \",sigma2_POL.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: Confidence Interval of Partialling Out Lasso\n",
    "Construct a two-sided 95 pct. confidence interval (CI) for $\\alpha$, which is asymptotically valid even in the high-dimensional regime. Compare with the \"standard\" CI implied by OLS (presuming conditionally homoskedastic errors). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CI_POL =  (39593.43, 42846.58)\n"
     ]
    }
   ],
   "source": [
    "q = norm.ppf(1-0.025)\n",
    "se_POL = np.sqrt(sigma2_POL/N)\n",
    "CI_POL = (((POL-q*se_POL).round(2),(POL+q*se_POL).round(2)))\n",
    "print(\"CI_POL = \",CI_POL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CI_OLS =  (array([39636.61]), array([40958.44]))\n"
     ]
    }
   ],
   "source": [
    "q = norm.ppf(1-0.025)\n",
    "SSR = np.sum(res_ols ** 2)\n",
    "N = y.shape[0]\n",
    "K = xx.shape[1]\n",
    "sigma2_ols = SSR/(N-K)\n",
    "var = sigma2_ols*la.inv(xx.T@xx)\n",
    "se_ols = np.sqrt(np.diagonal(var)).reshape(-1, 1)\n",
    "se_ols_d=se_ols[1]\n",
    "LS_d=LS[1]\n",
    "CI_OLS =  (((LS_d-q*se_ols_d).round(2),(LS_d+q*se_ols_d).round(2)))\n",
    "print(\"CI_OLS = \",CI_OLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6: Post Double Lasso\n",
    "Construct a two-sided 95 pct. CI using *double Lasso* $\\check{\\alpha}$ instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_BRT = 2428.92\n",
      "73438.2\n"
     ]
    }
   ],
   "source": [
    "penalty_BRTyx=BRT(X_stan,y)\n",
    "\n",
    "print(\"lambda_BRT =\",penalty_BRTyx.round(2))\n",
    "\n",
    "# Lasso on median house value\n",
    "fit_BRTyx=Lasso(alpha=penalty_BRTyx).fit(X_stan,y) \n",
    "coefs=fit_BRTyx.coef_\n",
    "print(coefs[0].round(2))\n",
    "# save residuals\n",
    "resyxz=y-fit_BRTyx.predict(X_stan) + d_stan*coefs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2056247723.5613732\n",
      "50295.90754509234\n",
      "PDL =  40883.0\n"
     ]
    }
   ],
   "source": [
    "#Use your previously saved residuals\n",
    "#If you want - you can compare with OLS (why is this possible?)\n",
    "from numpy import linalg as la\n",
    "def PDL_ols(resdz,resyxz,d):\n",
    "    denom = np.sum(resdz*d)\n",
    "    num = np.sum(resdz*resyxz)\n",
    "    return num/denom\n",
    "\n",
    "PDL=PDL_ols(resdz,resyxz,d)\n",
    "print(\"PDL = \",PDL.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma2_PDL =  4219298356.25\n"
     ]
    }
   ],
   "source": [
    "# variance\n",
    "resyzz=y-fit_BRTyx.predict(X_stan)\n",
    "N = resyzz.shape[0]\n",
    "num = np.sum(resdz**2*resyzz**2)/N\n",
    "denom = (np.sum(resdz**2)/N)**2\n",
    "sigma2_PDL = num/denom\n",
    "print(\"sigma2_PDL = \",sigma2_PDL.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CI_PDL =  (39992.36, 41773.64)\n"
     ]
    }
   ],
   "source": [
    "# conf interval\n",
    "q=norm.ppf(1-0.025)\n",
    "se_PDL=np.sqrt(sigma2_PDL/N)\n",
    "\n",
    "CI_PDL=(((PDL-q*se_PDL).round(2),(PDL+q*se_PDL).round(2)))\n",
    "print(\"CI_PDL = \",CI_PDL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7: Extensions\n",
    "\n",
    "To make the estimation problem more challenging:\n",
    "\n",
    "Repeat Exercises 1--5/6 after adding all control quadratics ($Z_1^2,\\dotsc,Z_p^2$) and first-order interactions ($Z_1Z_2,Z_1Z_3,\\dotsc,Z_{p-1}Z_{p}$). [Hints: Use <tt>sklearn.preprocessing.PolynomialFeatures</tt> for simple transformation. Your optimizer may not converge. Consider increasing the maximum number of iterations using the Lasso option <tt>max_iter=</tt>[your number].]\n",
    "\n",
    "Optional variations:\n",
    "* Repeat Exercises 1--5/6/7 using the Belloni-Chen-Chernozhukov-Hansen (BCCH) penalty level for each Lasso (which may be justified without any independence/homoskedasticity assumptions).\n",
    "* Repeat Exercises 1--5/6/7 using cross-validation (CV) for each Lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(2, include_bias=False)\n",
    "Z_2=poly.fit_transform(Z)\n",
    "Z_2_stan=standardize(Z_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_BRT = 2832.6\n"
     ]
    }
   ],
   "source": [
    "penalty_BRTyz_2=BRT(Z_2_stan,y)\n",
    "\n",
    "print(\"lambda_BRT =\",penalty_BRTyz_2.round(2))\n",
    "\n",
    "# Lasso on median house value\n",
    "fit_BRTyz_2=Lasso(alpha=penalty_BRTyz_2,max_iter=10000).fit(Z_2_stan,y) #,fit_intercept = False\n",
    "\n",
    "# save residuals\n",
    "resyz_2=y-fit_BRTyz_2.predict(Z_2_stan) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lasso on median income\n",
    "penalty_BRTdz_2=BRT(Z_2_stan,d)\n",
    "\n",
    "fit_BRTdz_2=Lasso(alpha=penalty_BRTdz_2).fit(Z_2_stan,d) #,fit_intercept = False\n",
    "\n",
    "# save residuals\n",
    "resdz_2=d-fit_BRTdz_2.predict(Z_2_stan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POL_2 =  41243.6\n",
      "LS =  [39512.12]\n"
     ]
    }
   ],
   "source": [
    "#Use your previously saved residuals\n",
    "#If you want - you can compare with OLS (why is this possible?)\n",
    "from numpy import linalg as la\n",
    "def POL_ols(x,y):\n",
    "    denom = np.sum(x**2)\n",
    "    num = np.sum(x*y)\n",
    "    return num/denom\n",
    "\n",
    "POL_2=POL_ols(resdz_2,resyz_2)\n",
    "print(\"POL_2 = \",POL_2.round(2))\n",
    "\n",
    "N=y.shape[0]\n",
    "xx_2=np.column_stack((np.ones(N),d,Z_2)).reshape(-1,2+Z_2.shape[1])\n",
    "yy=np.array(y).reshape(-1,1)\n",
    "LS_2=la.inv(xx_2.T@xx_2)@xx_2.T@yy\n",
    "print(\"LS = \",LS_2[1].round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma2_POL_2 =  15263885977.92\n"
     ]
    }
   ],
   "source": [
    "#Use your previously saved residuals\n",
    "N = resyz.shape[0]\n",
    "num = np.sum(resdz_2**2*resyz_2**2)/N\n",
    "denom = (np.sum(resdz_2**2)/N)**2\n",
    "sigma2_POL_2 = num/denom\n",
    "print(\"sigma2_POL_2 = \",sigma2_POL_2.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39549.59, 42937.6)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q=norm.ppf(1-0.025)\n",
    "se_POL_2=np.sqrt(sigma2_POL_2/N)\n",
    "CI_POL_2=(((POL_2-q*se_POL_2).round(2),(POL_2+q*se_POL_2).round(2)))\n",
    "CI_POL_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional variations:\n",
    "* Repeat Exercises 1--5/6/7 using the Belloni-Chen-Chernozhukov-Hansen (BCCH) penalty level for each Lasso (which may be justified without any independence/homoskedasticity assumptions).\n",
    "* Repeat Exercises 1--5/6/7 using cross-validation (CV) for each Lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "28b1ca885001685b2bc3a39df2ddd10ef1aa60bad7babe65fad257ff6b65d8b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
